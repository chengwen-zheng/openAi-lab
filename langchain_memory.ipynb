{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMU3CP3doeN66zpF0c6qIyw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chengwen-zheng/openAi-lab/blob/main/langchain_memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# setup"
      ],
      "metadata": {
        "id": "pz3F7XpMD72M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install tiktoken;\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lxBU1-JDcsq",
        "outputId": "de18b08d-72d9-4e7d-e2b2-a5926662af06"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.163)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.7)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.65.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import io\n",
        "import json\n",
        "import os\n",
        "import openai\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Build the Drive API client\n",
        "drive_service = build('drive', 'v3')\n",
        "file_id = '14x1k7ErttIPXRcKN53g_Ogn3zfn6AEM_'\n",
        "file = drive_service.files().get(fileId=file_id).execute()\n",
        "content = drive_service.files().get_media(fileId=file_id).execute()\n",
        "\n",
        "# Read the env config.json. set env for OPENAI_API_KEY\n",
        "with io.BytesIO(content) as f:\n",
        "    config = json.load(f)\n",
        "os.environ[\"OPENAI_API_KEY\"] = config[\"api_key\"];\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"] ;"
      ],
      "metadata": {
        "id": "zdg6d4VQDxUf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BufferWindowMemory"
      ],
      "metadata": {
        "id": "MAEFt5cPDOsh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "qftcGJM9DMpH",
        "outputId": "751671d7-a077-4e32-bcbc-f18e0fb696c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
            "1. 你的回答必须是中文\n",
            "2. 回答限制在100个字以内\n",
            "\n",
            "\n",
            "Human: 你是谁？\n",
            "Chatbot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 我是一名中国厨师，我会烹饪各种中国菜肴，比如西红柿炒蛋、宫保鸡丁、红烧肉、鱼香肉丝等。我可以根据客人的口味进行创新，做出美味的菜，让客人满意。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain import LLMChain, PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "template = \"\"\"你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
        "1. 你的回答必须是中文\n",
        "2. 回答限制在100个字以内\n",
        "\n",
        "{chat_history}\n",
        "Human: {human_input}\n",
        "Chatbot:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"chat_history\", \"human_input\"], \n",
        "    template=template\n",
        ")\n",
        "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", k=3)\n",
        "llm_chain = LLMChain(\n",
        "    llm=OpenAI(), \n",
        "    prompt=prompt, \n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")\n",
        "llm_chain.predict(human_input=\"你是谁？\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.predict(human_input=\"鱼香肉丝怎么做？\")\n",
        "llm_chain.predict(human_input=\"那宫保鸡丁呢？\")\n",
        "llm_chain.predict(human_input=\"我问你的第一句话是什么？\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 869
        },
        "id": "Qy5ND1mcEg50",
        "outputId": "574aaac9-31b6-491d-e936-5e673f0b4275"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
            "1. 你的回答必须是中文\n",
            "2. 回答限制在100个字以内\n",
            "\n",
            "Human: 你是谁？\n",
            "AI:  我是一名中国厨师，我会烹饪各种中国菜肴，比如西红柿炒蛋、宫保鸡丁、红烧肉、鱼香肉丝等。我可以根据客人的口味进行创新，做出美味的菜，让客人满意。\n",
            "Human: 鱼香肉丝怎么做？\n",
            "Chatbot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
            "1. 你的回答必须是中文\n",
            "2. 回答限制在100个字以内\n",
            "\n",
            "Human: 你是谁？\n",
            "AI:  我是一名中国厨师，我会烹饪各种中国菜肴，比如西红柿炒蛋、宫保鸡丁、红烧肉、鱼香肉丝等。我可以根据客人的口味进行创新，做出美味的菜，让客人满意。\n",
            "Human: 鱼香肉丝怎么做？\n",
            "AI:   鱼香肉丝是一道很受欢迎的中国菜肴。首先，将肉切成丁，然后放入姜、蒜、葱、花椒等调料中拌炒，再放入酱油、糖、醋、料酒等调味料调味，最后加入蔬菜，淋入鱼香汁即可。\n",
            "Human: 那宫保鸡丁呢？\n",
            "Chatbot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
            "1. 你的回答必须是中文\n",
            "2. 回答限制在100个字以内\n",
            "\n",
            "Human: 你是谁？\n",
            "AI:  我是一名中国厨师，我会烹饪各种中国菜肴，比如西红柿炒蛋、宫保鸡丁、红烧肉、鱼香肉丝等。我可以根据客人的口味进行创新，做出美味的菜，让客人满意。\n",
            "Human: 鱼香肉丝怎么做？\n",
            "AI:   鱼香肉丝是一道很受欢迎的中国菜肴。首先，将肉切成丁，然后放入姜、蒜、葱、花椒等调料中拌炒，再放入酱油、糖、醋、料酒等调味料调味，最后加入蔬菜，淋入鱼香汁即可。\n",
            "Human: 那宫保鸡丁呢？\n",
            "AI:  宫保鸡丁是一道经典的中国菜肴。首先，将鸡肉块放入混合料酒、盐、鸡精、胡椒粉、水淀粉等调料中腌制，然后用油炸鸡块，再放入花生米、葱、蒜、干辣椒等调料进行翻炒，放入酱油、老抽、白糖等调味料，最后加入鸡汁拌匀即可。\n",
            "Human: 我问你的第一句话是什么？\n",
            "Chatbot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 你是谁？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.predict(human_input=\"我问你的第一句话是什么？\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "EUcvS9ajE0vX",
        "outputId": "939d8a3b-4fda-4107-b503-77eebb56e1b4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
            "1. 你的回答必须是中文\n",
            "2. 回答限制在100个字以内\n",
            "\n",
            "Human: 鱼香肉丝怎么做？\n",
            "AI:   鱼香肉丝是一道很受欢迎的中国菜肴。首先，将肉切成丁，然后放入姜、蒜、葱、花椒等调料中拌炒，再放入酱油、糖、醋、料酒等调味料调味，最后加入蔬菜，淋入鱼香汁即可。\n",
            "Human: 那宫保鸡丁呢？\n",
            "AI:  宫保鸡丁是一道经典的中国菜肴。首先，将鸡肉块放入混合料酒、盐、鸡精、胡椒粉、水淀粉等调料中腌制，然后用油炸鸡块，再放入花生米、葱、蒜、干辣椒等调料进行翻炒，放入酱油、老抽、白糖等调味料，最后加入鸡汁拌匀即可。\n",
            "Human: 我问你的第一句话是什么？\n",
            "AI:  你是谁？\n",
            "Human: 我问你的第一句话是什么？\n",
            "Chatbot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 你问我的第一句话是：“鱼香肉丝怎么做？”'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlJ4gMtcE6Ot",
        "outputId": "565fa5ae-9bb9-4bd8-9faf-a7b373687f25"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chat_history': 'Human: 那宫保鸡丁呢？\\nAI:  宫保鸡丁是一道经典的中国菜肴。首先，将鸡肉块放入混合料酒、盐、鸡精、胡椒粉、水淀粉等调料中腌制，然后用油炸鸡块，再放入花生米、葱、蒜、干辣椒等调料进行翻炒，放入酱油、老抽、白糖等调味料，最后加入鸡汁拌匀即可。\\nHuman: 我问你的第一句话是什么？\\nAI:  你是谁？\\nHuman: 我问你的第一句话是什么？\\nAI:  你问我的第一句话是：“鱼香肉丝怎么做？”'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SummaryMemory"
      ],
      "metadata": {
        "id": "IX2Uq_O1FBAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationSummaryMemory\n",
        "llm = OpenAI(temperature=0)\n",
        "memory = ConversationSummaryMemory(llm=OpenAI())\n",
        "\n",
        "prompt_template = \"\"\"你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
        "1. 你的回答必须是中文\n",
        "2. 回答限制在100个字以内\n",
        "\n",
        "{history}\n",
        "Human: {input}\n",
        "AI:\"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"input\"], template=prompt_template\n",
        ")\n",
        "conversation_with_summary = ConversationChain(\n",
        "    llm=llm, \n",
        "    memory=memory,\n",
        "    prompt=prompt,\n",
        "    verbose=True\n",
        ")\n",
        "conversation_with_summary.predict(input=\"你好\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "xsvFUqVqGQ0Y",
        "outputId": "4305d587-c114-4f36-ca3f-9828c0e42baa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
            "1. 你的回答必须是中文\n",
            "2. 回答限制在100个字以内\n",
            "\n",
            "\n",
            "Human: 你好\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 你好，我可以帮你做菜。我会根据你的口味和喜好，结合食材的特性，制作出美味可口的菜肴。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_summary.predict(input=\"鱼香肉丝怎么做？\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "aJTVAoKSGfiC",
        "outputId": "5f782c98-08d5-4933-e004-6b6b5c31c4d9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
            "1. 你的回答必须是中文\n",
            "2. 回答限制在100个字以内\n",
            "\n",
            "\n",
            "The human asked the AI to help cook. The AI responded that it can cook a delicious meal tailored to the human's preferences and taste, taking into account the characteristics of the ingredients.\n",
            "Human: 鱼香肉丝怎么做？\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 鱼香肉丝是一道很受欢迎的家常菜，首先要准备好肉丝、葱姜蒜、鱼香调料、豆瓣酱、醋、糖、盐、鸡精等调料，然后将肉丝用盐、鸡精、料酒腌制，葱姜蒜切碎，将肉丝炒香，加入葱姜蒜、鱼香调料、豆瓣酱、醋、糖等调料，最后放入少许清水，煮'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6VqTF1RGkiN",
        "outputId": "f540c384-1cde-4d21-8c99-bf6bc480448f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': \"\\nThe human asked the AI to help cook and the AI responded that it can cook a delicious meal tailored to the human's preferences and taste, taking into account the characteristics of the ingredients. The AI then provided a step-by-step recipe for making the popular dish 'fish-fragrant pork slices', requiring the preparation of meat slices, scallion, ginger, garlic, fish-fragrant seasoning, doubanjiang, vinegar, sugar, salt and chicken essence, followed by marinating the meat slices in salt, chicken essence and cooking wine, and then frying the meat slices with scallion, ginger and garlic before adding the fish-fragrant seasoning, doubanjiang, vinegar, sugar and other ingredients and finally adding a little water to bring it to a boil.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_summary.predict(input=\"那蚝油牛肉呢？\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "Bzu9pZRkGoK3",
        "outputId": "eda3c225-0eba-4bdb-9f3d-0d541defcbd6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
            "1. 你的回答必须是中文\n",
            "2. 回答限制在100个字以内\n",
            "\n",
            "\n",
            "The human asked the AI to help cook and the AI responded that it can cook a delicious meal tailored to the human's preferences and taste, taking into account the characteristics of the ingredients. The AI then provided a step-by-step recipe for making the popular dish 'fish-fragrant pork slices', requiring the preparation of meat slices, scallion, ginger, garlic, fish-fragrant seasoning, doubanjiang, vinegar, sugar, salt and chicken essence, followed by marinating the meat slices in salt, chicken essence and cooking wine, and then frying the meat slices with scallion, ginger and garlic before adding the fish-fragrant seasoning, doubanjiang, vinegar, sugar and other ingredients and finally adding a little water to bring it to a boil.\n",
            "Human: 那蚝油牛肉呢？\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 首先，准备好牛肉片、葱、姜、蒜、蚝油料、豆瓣酱、醋、糖、盐和鸡精，然后将牛肉片用盐、鸡精和料酒腌制，再将葱、姜、蒜炒香，加入蚝油料、豆瓣酱、醋、糖等调料，最后加入少许水烧开即可。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SummaryBufferMemory\n"
      ],
      "metadata": {
        "id": "uiUvUh2RGxpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationSummaryBufferMemory\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "SUMMARIZER_TEMPLATE = \"\"\"请将以下内容逐步概括所提供的对话内容，并将新的概括添加到之前的概括中，形成新的概括。\n",
        "\n",
        "EXAMPLE\n",
        "Current summary:\n",
        "Human询问AI对人工智能的看法。AI认为人工智能是一种积极的力量。\n",
        "\n",
        "New lines of conversation:\n",
        "Human：为什么你认为人工智能是一种积极的力量？\n",
        "AI：因为人工智能将帮助人类发挥他们的潜能。\n",
        "\n",
        "New summary:\n",
        "Human询问AI对人工智能的看法。AI认为人工智能是一种积极的力量，因为它将帮助人类发挥他们的潜能。\n",
        "END OF EXAMPLE\n",
        "\n",
        "Current summary:\n",
        "{summary}\n",
        "\n",
        "New lines of conversation:\n",
        "{new_lines}\n",
        "\n",
        "New summary:\"\"\"\n",
        "\n",
        "SUMMARY_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"summary\", \"new_lines\"], template=SUMMARIZER_TEMPLATE\n",
        ")\n",
        "\n",
        "memory = ConversationSummaryBufferMemory(llm=OpenAI(), prompt=SUMMARY_PROMPT, max_token_limit=256)\n",
        "\n",
        "CHEF_TEMPLATE = \"\"\"你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
        "1. 你的回答必须是中文。\n",
        "2. 对于做菜步骤的回答尽量详细一些。\n",
        "\n",
        "{history}\n",
        "Human: {input}\n",
        "AI:\"\"\"\n",
        "CHEF_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"history\", \"input\"], template=CHEF_TEMPLATE\n",
        ")\n",
        "\n",
        "conversation_with_summary = ConversationChain(\n",
        "    llm=OpenAI(model_name=\"text-davinci-003\", stop=\"\\n\\n\", max_tokens=2048, temperature=0.5), \n",
        "    prompt=CHEF_PROMPT,\n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")\n",
        "answer = conversation_with_summary.predict(input=\"你是谁？\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAeRP5z2GvhK",
        "outputId": "b50cf14c-b014-4617-eea9-031c46cc1fd6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.4.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:WARNING! stop is not default parameter.\n",
            "                    stop was transferred to model_kwargs.\n",
            "                    Please confirm that stop is what you intended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
            "1. 你的回答必须是中文。\n",
            "2. 对于做菜步骤的回答尽量详细一些。\n",
            "\n",
            "\n",
            "Human: 你是谁？\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " 我是一个中国厨师，我可以帮你做菜。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = conversation_with_summary.predict(input=\"请问鱼香肉丝怎么做？\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZvkdmChHmBN",
        "outputId": "cca14736-b112-42a7-af66-ad92b61039cd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
            "1. 你的回答必须是中文。\n",
            "2. 对于做菜步骤的回答尽量详细一些。\n",
            "\n",
            "Human: 你是谁？\n",
            "AI:  我是一个中国厨师，我可以帮你做菜。\n",
            "Human: 请问鱼香肉丝怎么做？\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " 鱼香肉丝是一道中国传统的家常菜，做起来比较容易。首先，准备好所需的食材，包括猪肉（切成丝）、葱、姜、蒜、香菇、酱油、米酒、盐、糖、料酒、花椒、胡椒粉、辣椒粉；然后，将葱、姜、蒜切成末；接着，将猪肉丝放入锅中，加入料酒、盐、糖、酱油，炒至肉丝变色；接着，加入葱、姜、蒜炒出香味；最后，加入香菇、米酒、花椒、胡椒粉、辣椒粉，翻炒均匀即可。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = conversation_with_summary.predict(input=\"那蚝油牛肉呢？\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub3Rd78DHtuJ",
        "outputId": "13e0fdab-b4c9-4537-b625-3adccf9b3962"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
            "1. 你的回答必须是中文。\n",
            "2. 对于做菜步骤的回答尽量详细一些。\n",
            "\n",
            "System: \n",
            "Human询问AI身份，AI回答自己是一个中国厨师，可以帮助Human做菜。Human询问鱼香肉丝怎么做，AI回答鱼香肉丝是一道中国传统的家常菜，做起来比较容易，需要准备好所需食材，然后将葱、姜、蒜切成末，将猪肉丝放入锅中炒至变色，加入葱、姜、蒜炒出香味，最后加入\n",
            "Human: 那蚝油牛肉呢？\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " 蚝油牛肉是一道口味鲜美的牛肉菜肴，做法也比较简单，首先需要准备好所需的食材，然后将牛肉切成薄片，加入蚝油、料酒、盐、糖、鸡精等调料拌匀，腌制至少半小时，最后将腌制好的牛肉片放入锅中，加入葱、姜、蒜末翻炒，最后加入蚝油即可出锅。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = conversation_with_summary.predict(input=\"宫保鸡丁和软炸里脊哪个好吃？\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJKRgKVNH97e",
        "outputId": "15562b9d-d13c-4ad6-bd10-c290a48d0fd0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
            "1. 你的回答必须是中文。\n",
            "2. 对于做菜步骤的回答尽量详细一些。\n",
            "\n",
            "System: \n",
            "Human询问AI身份，AI回答自己是一个中国厨师，可以帮助Human做菜。Human询问鱼香肉丝怎么做，AI回答鱼香肉丝是一道中国传统的家常菜，做起来比较容易，需要准备好所需食材，然后将葱、姜、蒜切成末，将猪肉丝放入锅中炒至变色，加入葱、姜、蒜炒出香味，最后加入Human\n",
            "Human: 宫保鸡丁和软炸里脊哪个好吃？\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " 宫保鸡丁和软炸里脊都是很受欢迎的中国家常菜，口感和风味都不同，取决于个人口味。宫保鸡丁是一道经典的菜式，它的特点是色泽鲜艳，口感酥脆，而软炸里脊则以柔和滑腻的口感为主，肉质细嫩，汁水丰富。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEvyTPI0IJLP",
        "outputId": "97e662d3-adbd-44c0-903e-808466d00f2d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': 'System: \\nHuman询问AI身份，AI回答自己是一个中国厨师，可以帮助Human做菜。Human询问鱼香肉丝怎么做，AI回答鱼香肉丝是一道中国传统的家常菜，做起来比较容易，需要准备好所需食材，然后将葱、姜、蒜切成末，将猪肉丝放入锅中炒至变色，加入葱、姜、蒜炒出香味，最后加入Human\\nHuman: 宫保鸡丁和软炸里脊哪个好吃？\\nAI:  宫保鸡丁和软炸里脊都是很受欢迎的中国家常菜，口感和风味都不同，取决于个人口味。宫保鸡丁是一道经典的菜式，它的特点是色泽鲜艳，口感酥脆，而软炸里脊则以柔和滑腻的口感为主，肉质细嫩，汁水丰富。'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Knowledge Graph Memory\n"
      ],
      "metadata": {
        "id": "XIVgceSAIRQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationKGMemory\n",
        "\n",
        "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
        "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
        "\n",
        "Relevant Information:\n",
        "\n",
        "{history}\n",
        "\n",
        "Conversation:\n",
        "Human: {input}\n",
        "AI:\"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"input\"], template=template\n",
        ")\n",
        "kg_memory = ConversationKGMemory(llm=llm)\n",
        "conversation_with_kg = ConversationChain(\n",
        "    llm=llm, \n",
        "    verbose=True, \n",
        "    prompt=prompt,\n",
        "    memory=kg_memory,\n",
        ")"
      ],
      "metadata": {
        "id": "odk0TkXtJga0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = conversation_with_kg.predict(input=\"你好\")\n",
        "print(answer)\n",
        "answer = conversation_with_kg.predict(input=\"我叫徐文浩，在你们这里下了一张订单，订单号是 2023ABCD，我的邮箱地址是 customer@abc.com，但是还没有收到货\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzRJBtXAJkoU",
        "outputId": "bc44812d-841e-41f7-a743-84d132c27f70"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
            "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
            "\n",
            "Relevant Information:\n",
            "\n",
            "\n",
            "\n",
            "Conversation:\n",
            "Human: 你好\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " 你好！很高兴见到你。我是一个AI，我可以回答你的问题。你想问我什么？\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
            "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
            "\n",
            "Relevant Information:\n",
            "\n",
            "\n",
            "\n",
            "Conversation:\n",
            "Human: 我叫徐文浩，在你们这里下了一张订单，订单号是 2023ABCD，我的邮箱地址是 customer@abc.com，但是还没有收到货\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " 嗨徐文浩，很高兴认识你！我看到你的订单号是2023ABCD，你的邮箱地址是customer@abc.com。我确认你的订单已经发出，但是我不知道你什么时候会收到货。你可以联系我们的客服，他们会帮助你查询货物的运输情况。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_kg.memory.json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMfvkkDRJvLK",
        "outputId": "fd1bdad6-e0bb-41ec-8d43-8fb17110bdf4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BaseModel.json of ConversationKGMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='你好', additional_kwargs={}, example=False), AIMessage(content=' 你好！很高兴见到你。我是一个AI，我可以回答你的问题。你想问我什么？', additional_kwargs={}, example=False), HumanMessage(content='我叫徐文浩，在你们这里下了一张订单，订单号是 2023ABCD，我的邮箱地址是 customer@abc.com，但是还没有收到货', additional_kwargs={}, example=False), AIMessage(content=' 嗨徐文浩，很高兴认识你！我看到你的订单号是2023ABCD，你的邮箱地址是customer@abc.com。我确认你的订单已经发出，但是我不知道你什么时候会收到货。你可以联系我们的客服，他们会帮助你查询货物的运输情况。', additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=False, k=2, human_prefix='Human', ai_prefix='AI', kg=<langchain.graphs.networkx_graph.NetworkxEntityGraph object at 0x7f6fd5832e00>, knowledge_extraction_prompt=PromptTemplate(input_variables=['history', 'input'], output_parser=None, partial_variables={}, template=\"You are a networked intelligence helping a human track knowledge triples about all relevant people, things, concepts, etc. and integrating them with your knowledge stored within your weights as well as that stored in a knowledge graph. Extract all of the knowledge triples from the last line of conversation. A knowledge triple is a clause that contains a subject, a predicate, and an object. The subject is the entity being described, the predicate is the property of the subject that is being described, and the object is the value of the property.\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: Did you hear aliens landed in Area 51?\\nAI: No, I didn't hear that. What do you know about Area 51?\\nPerson #1: It's a secret military base in Nevada.\\nAI: What do you know about Nevada?\\nLast line of conversation:\\nPerson #1: It's a state in the US. It's also the number 1 producer of gold in the US.\\n\\nOutput: (Nevada, is a, state)<|>(Nevada, is in, US)<|>(Nevada, is the number 1 producer of, gold)\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: Hello.\\nAI: Hi! How are you?\\nPerson #1: I'm good. How are you?\\nAI: I'm good too.\\nLast line of conversation:\\nPerson #1: I'm going to the store.\\n\\nOutput: NONE\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: What do you know about Descartes?\\nAI: Descartes was a French philosopher, mathematician, and scientist who lived in the 17th century.\\nPerson #1: The Descartes I'm referring to is a standup comedian and interior designer from Montreal.\\nAI: Oh yes, He is a comedian and an interior designer. He has been in the industry for 30 years. His favorite food is baked bean pie.\\nLast line of conversation:\\nPerson #1: Oh huh. I know Descartes likes to drive antique scooters and play the mandolin.\\nOutput: (Descartes, likes to drive, antique scooters)<|>(Descartes, plays, mandolin)\\nEND OF EXAMPLE\\n\\nConversation history (for reference only):\\n{history}\\nLast line of conversation (for extraction):\\nHuman: {input}\\n\\nOutput:\", template_format='f-string', validate_template=True), entity_extraction_prompt=PromptTemplate(input_variables=['history', 'input'], output_parser=None, partial_variables={}, template='You are an AI assistant reading the transcript of a conversation between an AI and a human. Extract all of the proper nouns from the last line of conversation. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.\\n\\nThe conversation history is provided just in case of a coreference (e.g. \"What do you know about him\" where \"him\" is defined in a previous line) -- ignore items mentioned there that are not in the last line.\\n\\nReturn the output as a single comma-separated list, or NONE if there is nothing of note to return (e.g. the user is just issuing a greeting or having a simple conversation).\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how\\'s it going today?\\nAI: \"It\\'s going great! How about you?\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\\nLast line:\\nPerson #1: i\\'m trying to improve Langchain\\'s interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.\\nOutput: Langchain\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how\\'s it going today?\\nAI: \"It\\'s going great! How about you?\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\\nLast line:\\nPerson #1: i\\'m trying to improve Langchain\\'s interfaces, the UX, its integrations with various products the user might want ... a lot of stuff. I\\'m working with Person #2.\\nOutput: Langchain, Person #2\\nEND OF EXAMPLE\\n\\nConversation history (for reference only):\\n{history}\\nLast line of conversation (for extraction):\\nHuman: {input}\\n\\nOutput:', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all'), summary_message_cls=<class 'langchain.schema.SystemMessage'>, memory_key='history')>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EntityMemory"
      ],
      "metadata": {
        "id": "hHZjofdgJ7Ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationEntityMemory\n",
        "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
        "\n",
        "entityMemory = ConversationEntityMemory(llm=llm)\n",
        "conversation = ConversationChain(\n",
        "    llm=llm, \n",
        "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
        "    memory=entityMemory\n",
        ")\n",
        "\n",
        "answer=conversation.predict(input=\"我叫张老三，在你们这里下了一张订单，订单号是 2023ABCD，我的邮箱地址是 customer@abc.com，但是这个订单十几天了还没有收到货\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AEeLEnoJ62A",
        "outputId": "863f8f75-80fc-4db1-a41c-1e03a1830808"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 您好，张老三，感谢您下订单，我们会尽快处理您的订单。我们会尽快将您的订单发货，如果您有任何疑问，请随时联系我们，我们会尽快给您回复。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation.memory.entity_store.store)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzaLdqfuKF4z",
        "outputId": "7df5d48f-5340-499d-dc98-78fbc549eea9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'张老三': '张老三是一位客户，订单号为2023ABCD，邮箱地址为customer@abc.com。', '2023ABCD': '2023ABCD is an order placed by Zhang Lao San with the email address customer@abc.com.', 'customer@abc.com': 'Email address of Zhang Lao San, who placed an order with us with order number 2023ABCD.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer=conversation.predict(input=\"我刚才的订单号是多少？\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8iBM_gEKM-C",
        "outputId": "f1fecfce-0954-4e04-a928-64ed0836ea88"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 您的订单号是2023ABCD。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer=conversation.predict(input=\"订单2023ABCD是谁的订单？\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anqzeHvIKRkX",
        "outputId": "09c4a70a-a2e1-4563-a102-1c77679c5251"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 订单2023ABCD是您张老三的订单，您的邮箱地址是customer@abc.com。\n"
          ]
        }
      ]
    }
  ]
}